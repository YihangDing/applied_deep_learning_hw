{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_part3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "khow9NztfzP-",
        "colab_type": "code",
        "outputId": "d934f7eb-4b40-40a7-95af-204f06e3e05b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 332.1MB 67kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 419kB 12.7MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 61kB 31.0MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 10.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zAJH1PgDgJnQ",
        "colab_type": "code",
        "outputId": "8b5933b5-e46e-4bc9-ddba-b16bd9f559d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu # https://github.com/mjpost/sacreBLEU"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading https://files.pythonhosted.org/packages/12/5b/7196b11bca204cb6ca9000b5dc910e809081f224c73ef28e9991080e4e51/sacrebleu-1.3.1.tar.gz\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Building wheels for collected packages: sacrebleu\n",
            "  Building wheel for sacrebleu (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/56/c0/fb/1c7f9b3a71f64cdf86291cc645596f71746807bf2f72b3c1dd\n",
            "Successfully built sacrebleu\n",
            "Installing collected packages: sacrebleu\n",
            "Successfully installed sacrebleu-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "26B4FWZlyQAY",
        "colab_type": "code",
        "outputId": "f82eecd0-9553-4f29-b042-a173fbc370e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip spa-eng"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  spa-eng.zip\n",
            "   creating: spa-eng/\n",
            "  inflating: spa-eng/_about.txt      \n",
            "  inflating: spa-eng/spa.txt         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s9C2PU2KyrO9",
        "colab_type": "code",
        "outputId": "0d1fc85d-3234-4205-ec1c-c99f0d0584e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls spa-eng"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_about.txt  spa.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RdHt6GALgJqO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import sacrebleu\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import unicodedata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQsKur7DhuH5",
        "colab_type": "code",
        "outputId": "921c2ec1-6be0-4578-aa1a-56a6665e0810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-alpha0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "eLydB4PpypLZ",
        "colab_type": "code",
        "outputId": "2146c603-6d92-4666-b705-28b7b11b4561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "with open('spa-eng/spa.txt') as f:\n",
        "  sentences=[]\n",
        "  sentences_reverse=[]\n",
        "  for _ in range(1000):\n",
        "    tmp=f.readline()\n",
        "    tmpl=tmp.split('\\t')\n",
        "    sentences.append(tmpl)\n",
        "sentences[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Go.', 'Ve.\\n'],\n",
              " ['Go.', 'Vete.\\n'],\n",
              " ['Go.', 'Vaya.\\n'],\n",
              " ['Go.', 'Váyase.\\n'],\n",
              " ['Hi.', 'Hola.\\n']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "iLeh3f4VgJyd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(s):\n",
        "  # for details, see https://www.tensorflow.org/alpha/tutorials/sequences/nmt_with_attention\n",
        "  s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "  s = s.strip()\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  s = '<start> ' + s + ' <end>'\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_XD48hhgJ53",
        "colab_type": "code",
        "outputId": "114c490b-1d7f-4a46-f85d-2cce479cf503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Original:\", sentences[0])\n",
        "sentences = [(preprocess(source), preprocess(target)) for (source, target) in sentences]\n",
        "print(\"Preprocessed:\", sentences[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: ['Go.', 'Ve.\\n']\n",
            "Preprocessed: ('<start> Go . <end>', '<start> Ve . <end>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BswiuexJgJ_O",
        "colab_type": "code",
        "outputId": "2ca751d5-daad-4f7d-ccd9-cb5fa4d7a350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#pair english & spanish\n",
        "source_sentences, target_sentences = list(zip(*sentences))\n",
        "source_sentences[0],target_sentences[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<start> Go . <end>', '<start> Ve . <end>')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "dEavGQFDgKE4",
        "colab_type": "code",
        "outputId": "e9c6da8f-e550-46a2-d853-4d6fe6ece1b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#tokenize source data\n",
        "source_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_tokenizer.fit_on_texts(source_sentences)\n",
        "source_data = source_tokenizer.texts_to_sequences(source_sentences)\n",
        "print(\"Sequence:\", source_data[0])\n",
        "source_data = tf.keras.preprocessing.sequence.pad_sequences(source_data, padding='post')\n",
        "print(\"Padded:\", source_data[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [1, 10, 3, 2]\n",
            "Padded: [ 1 10  3  2  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YEuOTzwegKC5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tokenize target data \n",
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_tokenizer.fit_on_texts(target_sentences)\n",
        "target_data = target_tokenizer.texts_to_sequences(target_sentences)\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgA8z6CWgJ8h",
        "colab_type": "code",
        "outputId": "65123a5c-0d17-42fa-8b01-a1811659fdc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels = np.zeros(target_data.shape)\n",
        "target_labels[:,0:target_data.shape[1] -1] = target_data[:,1:]\n",
        "\n",
        "print(\"Target sequence\", target_data[0])\n",
        "print(\"Target label\", target_labels[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target sequence [ 1 39  3  2  0  0  0  0  0]\n",
            "Target label [39.  3.  2.  0.  0.  0.  0.  0.  0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1C-je5um0pwN",
        "colab_type": "code",
        "outputId": "32a9168f-7853-4306-861a-5d314d3886e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# reverse: Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels_reverse = np.zeros(source_data.shape)\n",
        "target_labels_reverse[:,0:source_data.shape[1] -1] = source_data[:,1:]\n",
        "\n",
        "print(\"Target sequence reversed\", source_data[0])\n",
        "print(\"Target label reversed\", target_labels_reverse[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target sequence reversed [ 1 10  3  2  0  0  0]\n",
            "Target label reversed [10.  3.  2.  0.  0.  0.  0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3RslwJbDgJ3I",
        "colab_type": "code",
        "outputId": "4ae960b5-1dee-441f-cdf7-6b35e34a27ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "source_vocab_size = len(source_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "source_vocab_size,target_vocab_size"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(373, 822)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "W-EGQwVRgJ0m",
        "colab_type": "code",
        "outputId": "61b3974a-c461-464f-876a-2b63d8240be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "def decode(encoded, tokenizer):\n",
        "  for number in encoded:\n",
        "    if number !=0:\n",
        "      print (\"%d -> %s\" % (number, tokenizer.index_word[number]))\n",
        "      \n",
        "decode(source_data[0], source_tokenizer)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> <start>\n",
            "10 -> go\n",
            "3 -> .\n",
            "2 -> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ah_5XbSGgJtI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "#dataset for 2 cond separately\n",
        "dataset = tf.data.Dataset.from_tensor_slices((source_data, target_data, target_labels)).batch(batch_size)\n",
        "dataset_reverse = tf.data.Dataset.from_tensor_slices((target_data, source_data, target_labels_reverse)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mkVgO9TkHz4C",
        "colab_type": "code",
        "outputId": "d191782b-2e2a-4c2e-eda1-ec60f1bbc53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "example_batch = next(iter(dataset_reverse))\n",
        "source, target, taget_labels = example_batch\n",
        "print(\"Shapes:\", source.shape, target.shape, taget_labels.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes: (5, 9) (5, 7) (5, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T5sHioWfgjTv",
        "colab_type": "code",
        "outputId": "2baf0e6c-d7ba-456c-cd6f-f9313d30b7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "example_batch = next(iter(dataset))\n",
        "source, target, taget_labels = example_batch\n",
        "print(\"Shapes:\", source.shape, target.shape, taget_labels.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes: (5, 7) (5, 9) (5, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TAjcgsNxgjZ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 32\n",
        "rnn_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uz7reJWegjfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self,size):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(size,\n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)        \n",
        "    return output, state\n",
        "  \n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, rnn_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1YMBKMtLgjmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(size, \n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    logits = self.dense(output)\n",
        "    return logits, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKqdE4lEgjjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#init encoder, decoder\n",
        "encoder = Encoder(source_vocab_size)\n",
        "decoder = Decoder(target_vocab_size)\n",
        "\n",
        "encoder_reverse=Encoder(target_vocab_size)\n",
        "decoder_reverse=Decoder(source_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hWimers-gjXP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def calc_loss(targets, logits):\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  return crossentropy(targets, logits, sample_weight=mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xuVjZhObg2X7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def translate(idx=None):\n",
        "  \n",
        "    if idx == None: \n",
        "      idx = np.random.choice(len(sentences))\n",
        "\n",
        "    \n",
        "    input_sent = source_data[idx]\n",
        "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "    \n",
        "    hidden_state = encoder.init_state(batch_size=1)\n",
        "    output, hidden_state = encoder(input_sent, hidden_state)\n",
        "    \n",
        "    decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "    out_words = []\n",
        "    \n",
        "    decoder_state = hidden_state\n",
        "\n",
        "    while True:\n",
        "      \n",
        "        decoder_output, decoder_state = decoder(decoder_input, decoder_state)\n",
        "        decoder_input = tf.argmax(decoder_output, -1)\n",
        "        word_idx = decoder_input.numpy()[0][0]\n",
        "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "        # before the decoder is trained, just stop translating and return\n",
        "        # what we have)\n",
        "        if word_idx == 0: \n",
        "          out_words.append('<end>')\n",
        "        else:\n",
        "          out_words.append(target_tokenizer.index_word[word_idx])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "          break\n",
        "          \n",
        "    translation = ' '.join(out_words)    \n",
        "    return sentences[idx][0], sentences[idx][1], translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T2jefNsN3XZg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def translate_reverse(idx=None):\n",
        "  \n",
        "    if idx == None: \n",
        "      idx = np.random.choice(len(sentences))\n",
        "    \n",
        "    input_sent = target_data[idx]\n",
        "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "    \n",
        "    hidden_state = encoder_reverse.init_state(batch_size=1)\n",
        "    output, hidden_state = encoder_reverse(input_sent, hidden_state)\n",
        "    \n",
        "    decoder_input = tf.expand_dims([source_tokenizer.word_index['<start>']], 0)\n",
        "    out_words = []\n",
        "    \n",
        "    decoder_state = hidden_state\n",
        "\n",
        "    while True:\n",
        "      \n",
        "        decoder_output, decoder_state = decoder_reverse(decoder_input, decoder_state)\n",
        "        decoder_input = tf.argmax(decoder_output, -1)\n",
        "        word_idx = decoder_input.numpy()[0][0]\n",
        "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "        # before the decoder is trained, just stop translating and return\n",
        "        # what we have)\n",
        "        if word_idx == 0: \n",
        "          out_words.append('<end>')\n",
        "        else:\n",
        "          out_words.append(source_tokenizer.index_word[word_idx])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "          break\n",
        "          \n",
        "    translation = ' '.join(out_words)    \n",
        "    return sentences[idx][1], sentences[idx][0], translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oMuxE6l2g2gm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-E5-xNPBg2kU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step(source_seq, target_seq, target_labels, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5S3a4PkOGguc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step_reverse(source_seq, target_seq, target_labels, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder_reverse(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder_reverse(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder_reverse.trainable_variables + decoder_reverse.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "40tCzxcqg2oG",
        "colab_type": "code",
        "outputId": "4e2a48d6-0408-4292-bcab-7b10e48257df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 200\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states = encoder.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
        "      loss = train_step(source_seq, target_seq, target_labels, en_initial_states)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "      input_sent, target_sent, translation = translate()\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 1.9348, Time 6.78 sec\n",
            "Input: <start> Look away . <end>\n",
            "Target: <start> Miren para otro lado . <end>\n",
            "Translation: . <end>\n",
            "\n",
            "Epoch #10, Loss 1.2568, Time 0.85 sec\n",
            "Input: <start> Go . <end>\n",
            "Target: <start> Vayase . <end>\n",
            "Translation: ven a tomas . <end>\n",
            "\n",
            "Epoch #20, Loss 0.9815, Time 0.86 sec\n",
            "Input: <start> I moved . <end>\n",
            "Target: <start> Me he mudado . <end>\n",
            "Translation: tom se quedo . <end>\n",
            "\n",
            "Epoch #30, Loss 0.7357, Time 0.85 sec\n",
            "Input: <start> We saw it . <end>\n",
            "Target: <start> Lo vimos . <end>\n",
            "Translation: lo echo de falta . <end>\n",
            "\n",
            "Epoch #40, Loss 0.5728, Time 0.85 sec\n",
            "Input: <start> Sit down ! <end>\n",
            "Target: <start> Sentate ! <end>\n",
            "Translation: vuelve otra vez . <end>\n",
            "\n",
            "Epoch #50, Loss 0.4719, Time 0.88 sec\n",
            "Input: <start> Seize him ! <end>\n",
            "Target: <start> Cogedlo ! <end>\n",
            "Translation: buen trabajo ! <end>\n",
            "\n",
            "Epoch #60, Loss 0.3352, Time 0.86 sec\n",
            "Input: <start> Bring help . <end>\n",
            "Target: <start> Traed ayuda . <end>\n",
            "Translation: traed comida . <end>\n",
            "\n",
            "Epoch #70, Loss 0.2671, Time 0.86 sec\n",
            "Input: <start> Follow me . <end>\n",
            "Target: <start> Sigueme . <end>\n",
            "Translation: sigueme . <end>\n",
            "\n",
            "Epoch #80, Loss 0.2506, Time 0.85 sec\n",
            "Input: <start> Don t move . <end>\n",
            "Target: <start> No se muevan . <end>\n",
            "Translation: no se muevan . <end>\n",
            "\n",
            "Epoch #90, Loss 0.1685, Time 0.87 sec\n",
            "Input: <start> I m full . <end>\n",
            "Target: <start> Estoy lleno . <end>\n",
            "Translation: estoy sin dinero . <end>\n",
            "\n",
            "Epoch #100, Loss 0.1555, Time 0.99 sec\n",
            "Input: <start> I fainted . <end>\n",
            "Target: <start> Perdi la consciencia . <end>\n",
            "Translation: perdi la consciencia . <end>\n",
            "\n",
            "Epoch #110, Loss 0.1513, Time 0.87 sec\n",
            "Input: <start> Stand by . <end>\n",
            "Target: <start> Preparate . <end>\n",
            "Translation: un momento . <end>\n",
            "\n",
            "Epoch #120, Loss 0.1343, Time 0.85 sec\n",
            "Input: <start> Go inside . <end>\n",
            "Target: <start> Entra . <end>\n",
            "Translation: entra . <end>\n",
            "\n",
            "Epoch #130, Loss 0.1399, Time 0.85 sec\n",
            "Input: <start> Fire ! <end>\n",
            "Target: <start> Fuego ! <end>\n",
            "Translation: incendio ! <end>\n",
            "\n",
            "Epoch #140, Loss 0.1480, Time 1.02 sec\n",
            "Input: <start> Have fun . <end>\n",
            "Target: <start> Pasenla bien . <end>\n",
            "Translation: pasala bien . <end>\n",
            "\n",
            "Epoch #150, Loss 0.1322, Time 0.85 sec\n",
            "Input: <start> I m sorry . <end>\n",
            "Target: <start> Lo siento . <end>\n",
            "Translation: lo siento . <end>\n",
            "\n",
            "Epoch #160, Loss 0.1731, Time 0.86 sec\n",
            "Input: <start> Move over . <end>\n",
            "Target: <start> Hazte a un lado . <end>\n",
            "Translation: deja sitio . <end>\n",
            "\n",
            "Epoch #170, Loss 0.1295, Time 0.86 sec\n",
            "Input: <start> Join us . <end>\n",
            "Target: <start> Unete a nosotros . <end>\n",
            "Translation: se parte nuestra . <end>\n",
            "\n",
            "Epoch #180, Loss 0.1299, Time 0.86 sec\n",
            "Input: <start> She tried . <end>\n",
            "Target: <start> Ella lo intento . <end>\n",
            "Translation: ella lo probo . <end>\n",
            "\n",
            "Epoch #190, Loss 0.1351, Time 0.99 sec\n",
            "Input: <start> Tom left . <end>\n",
            "Target: <start> Tom se fue . <end>\n",
            "Translation: tom se fue . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y0Dklr7Kg2fS",
        "colab_type": "code",
        "outputId": "f7c5ab47-609a-4db4-d1d9-b4e351a3939b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#calculate BLEU score\n",
        "references, hypotheses = [], []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  input_sent, target_sent, translation = translate()\n",
        "  references.append(target_sent)\n",
        "  hypotheses.append(\"<start> \" + translation)\n",
        "  \n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses, [references])\n",
        "print(results)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=28.890513844757614, counts=[3901, 1813, 752, 207], totals=[5223, 4223, 3223, 2223], precisions=[74.68887612483248, 42.931565237982475, 23.33229910021719, 9.31174089068826], bp=1.0, sys_len=5223, ref_len=5172)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Ih-CJP6uvwK",
        "colab_type": "code",
        "outputId": "0b9b47cf-ab4b-4df0-85e1-a72c198cbbe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "#train reverse\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states = encoder_reverse.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset_reverse):\n",
        "      loss_re = train_step_reverse(source_seq, target_seq, target_labels, en_initial_states)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "      input_sent, target_sent, translation = translate_reverse()\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 0.1234, Time 2.97 sec\n",
            "Input: <start> Estoy debil . <end>\n",
            "Target: <start> I m weak . <end>\n",
            "Translation: tom . <end>\n",
            "\n",
            "Epoch #10, Loss 0.1234, Time 0.87 sec\n",
            "Input: <start> Hace frio . <end>\n",
            "Target: <start> It s cold . <end>\n",
            "Translation: i m first . <end>\n",
            "\n",
            "Epoch #20, Loss 0.1234, Time 0.86 sec\n",
            "Input: <start> Lo echo en falta . <end>\n",
            "Target: <start> I miss it . <end>\n",
            "Translation: i ll wait . <end>\n",
            "\n",
            "Epoch #30, Loss 0.1234, Time 0.88 sec\n",
            "Input: <start> Espere . <end>\n",
            "Target: <start> I waited . <end>\n",
            "Translation: i ll wait . <end>\n",
            "\n",
            "Epoch #40, Loss 0.1234, Time 0.86 sec\n",
            "Input: <start> Estoy perfectamente . <end>\n",
            "Target: <start> I m okay . <end>\n",
            "Translation: i m alone . <end>\n",
            "\n",
            "Epoch #50, Loss 0.1234, Time 1.00 sec\n",
            "Input: <start> Preguntele a cualquiera . <end>\n",
            "Target: <start> Ask anyone . <end>\n",
            "Translation: ask anyone . <end>\n",
            "\n",
            "Epoch #60, Loss 0.1234, Time 0.87 sec\n",
            "Input: <start> Tomas miente . <end>\n",
            "Target: <start> Tom lies . <end>\n",
            "Translation: tom s tom . <end>\n",
            "\n",
            "Epoch #70, Loss 0.1234, Time 0.88 sec\n",
            "Input: <start> No puede ser ! <end>\n",
            "Target: <start> No way ! <end>\n",
            "Translation: no way ! <end>\n",
            "\n",
            "Epoch #80, Loss 0.1234, Time 0.87 sec\n",
            "Input: <start> Siguele . <end>\n",
            "Target: <start> Follow him . <end>\n",
            "Translation: follow him . <end>\n",
            "\n",
            "Epoch #90, Loss 0.1234, Time 0.88 sec\n",
            "Input: <start> Ha llegado la hora . <end>\n",
            "Target: <start> It s time . <end>\n",
            "Translation: it s time . <end>\n",
            "\n",
            "Epoch #100, Loss 0.1234, Time 0.88 sec\n",
            "Input: <start> Besa a Tomas . <end>\n",
            "Target: <start> Kiss Tom . <end>\n",
            "Translation: kiss tom . <end>\n",
            "\n",
            "Epoch #110, Loss 0.1234, Time 0.86 sec\n",
            "Input: <start> Orale ! <end>\n",
            "Target: <start> Go away . <end>\n",
            "Translation: go away . <end>\n",
            "\n",
            "Epoch #120, Loss 0.1234, Time 0.87 sec\n",
            "Input: <start> Tom se inclino . <end>\n",
            "Target: <start> Tom bowed . <end>\n",
            "Translation: tom bowed . <end>\n",
            "\n",
            "Epoch #130, Loss 0.1234, Time 0.88 sec\n",
            "Input: <start> Es bueno . <end>\n",
            "Target: <start> It s good . <end>\n",
            "Translation: it s good . <end>\n",
            "\n",
            "Epoch #140, Loss 0.1234, Time 1.00 sec\n",
            "Input: <start> Buen tiro ! <end>\n",
            "Target: <start> Nice shot ! <end>\n",
            "Translation: nice shot ! <end>\n",
            "\n",
            "Epoch #150, Loss 0.1234, Time 0.88 sec\n",
            "Input: <start> Tomen esto . <end>\n",
            "Target: <start> Take this . <end>\n",
            "Translation: take this . <end>\n",
            "\n",
            "Epoch #160, Loss 0.1234, Time 0.87 sec\n",
            "Input: <start> Firma esto . <end>\n",
            "Target: <start> Sign this . <end>\n",
            "Translation: sign this . <end>\n",
            "\n",
            "Epoch #170, Loss 0.1234, Time 0.86 sec\n",
            "Input: <start> Pase . <end>\n",
            "Target: <start> Come on in . <end>\n",
            "Translation: come on in . <end>\n",
            "\n",
            "Epoch #180, Loss 0.1234, Time 0.87 sec\n",
            "Input: <start> Menti . <end>\n",
            "Target: <start> I lied . <end>\n",
            "Translation: i lied . <end>\n",
            "\n",
            "Epoch #190, Loss 0.1234, Time 0.86 sec\n",
            "Input: <start> Lo siento . <end>\n",
            "Target: <start> I m sorry . <end>\n",
            "Translation: i m sorry . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UAw8VmsTuv2j",
        "colab_type": "code",
        "outputId": "594a6d6f-f91d-4938-f56d-6de200172351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#calculate BLEU score for reversed translation\n",
        "references_reverse, hypotheses_reverse = [], []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  input_sent, target_sent, translation = translate_reverse()\n",
        "  references_reverse.append(target_sent)\n",
        "  hypotheses_reverse.append(\"<start> \" + translation)\n",
        "  \n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses_reverse, [references_reverse])\n",
        "print(results)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=36.063774172316585, counts=[4161, 2129, 1137, 299], totals=[5325, 4325, 3325, 2325], precisions=[78.14084507042253, 49.225433526011564, 34.19548872180451, 12.86021505376344], bp=1.0, sys_len=5325, ref_len=5310)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZPF8iUGXuv0O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#translate to spanish\n",
        "input_list,eng_spa=[],[]\n",
        "for i in range(len(sentences)):\n",
        "  input_sent,_, translation = translate(idx=i) \n",
        "  eng_spa.append('<start> '+translation)\n",
        "  input_list.append(input_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dl0WqttRs9B5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tokenize translated sentences\n",
        "target_data = target_tokenizer.texts_to_sequences(eng_spa)\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ruyAfg8hsMAT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#translate back to english\n",
        "spa_eng=[]\n",
        "for i in range(len(sentences)):\n",
        "  _,_, translation = translate_reverse(idx=i) \n",
        "  spa_eng.append('<start> '+translation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nIQ1vAjvxku4",
        "colab_type": "code",
        "outputId": "5bee44dd-bcd8-44bb-cf05-ba98c5ceb598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "#examples\n",
        "print('Target | To_Spanish | To_English:')\n",
        "for i in range(5,15):\n",
        "  print(input_list[i][7:-5],'|',eng_spa[i][7:-5],'|',spa_eng[i][7:-5])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target | To_Spanish | To_English:\n",
            " Run !  |  corre !  |  run ! \n",
            " Run .  |  corred .  |  run . \n",
            " Who ?  |  ¿ quien ?  |  who ? \n",
            " Fire !  |  fuego !  |  fire ! \n",
            " Fire !  |  fuego !  |  fire ! \n",
            " Fire !  |  fuego !  |  fire ! \n",
            " Help !  |  auxilio !  |  help ! \n",
            " Help !  |  auxilio !  |  help ! \n",
            " Help !  |  auxilio !  |  help ! \n",
            " Jump !  |  salta !  |  jump ! \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zD5D0bISuvb4",
        "colab_type": "code",
        "outputId": "16c7f509-e52f-4414-a929-bbf641f29a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#calculate final BLEU score\n",
        "results = sacrebleu.raw_corpus_bleu(spa_eng, [input_list])\n",
        "print(results)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=36.29426557834601, counts=[4171, 2137, 1149, 302], totals=[5326, 4326, 3326, 2326], precisions=[78.31393165602704, 49.39898289412852, 34.54600120264582, 12.98366294067068], bp=1.0, sys_len=5326, ref_len=5317)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_KGYy6-4uaXk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}