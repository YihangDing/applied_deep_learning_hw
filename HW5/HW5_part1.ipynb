{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_part1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "khow9NztfzP-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zAJH1PgDgJnQ",
        "colab_type": "code",
        "outputId": "78c9c928-13b4-4ef3-ebca-0c20511fe6b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu # https://github.com/mjpost/sacreBLEU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "26B4FWZlyQAY",
        "colab_type": "code",
        "outputId": "580a4fc0-dced-4bf4-b87a-39ec37dd7434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip spa-eng"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  spa-eng.zip\n",
            "replace spa-eng/_about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s9C2PU2KyrO9",
        "colab_type": "code",
        "outputId": "538775f9-6e4b-49ff-ccdd-2e2e198c5a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls spa-eng"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_about.txt  spa.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RdHt6GALgJqO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import sacrebleu\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import unicodedata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQsKur7DhuH5",
        "colab_type": "code",
        "outputId": "df77a372-7cf8-4124-8180-d5eca9bf8ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-alpha0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "metadata": {
        "id": "eLydB4PpypLZ",
        "colab_type": "code",
        "outputId": "c9bbe331-d9f4-4a6d-9c75-cd74c4add1dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "with open('spa-eng/spa.txt') as f:\n",
        "  sentences=[]\n",
        "  for _ in range(5000):\n",
        "    tmp=f.readline()\n",
        "    sentences.append(tmp.split('\\t'))\n",
        "sentences[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Go.', 'Ve.\\n'],\n",
              " ['Go.', 'Vete.\\n'],\n",
              " ['Go.', 'Vaya.\\n'],\n",
              " ['Go.', 'Váyase.\\n'],\n",
              " ['Hi.', 'Hola.\\n'],\n",
              " ['Run!', '¡Corre!\\n'],\n",
              " ['Run.', 'Corred.\\n'],\n",
              " ['Who?', '¿Quién?\\n'],\n",
              " ['Fire!', '¡Fuego!\\n'],\n",
              " ['Fire!', '¡Incendio!\\n']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "metadata": {
        "id": "iLeh3f4VgJyd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(s):\n",
        "  # for details, see https://www.tensorflow.org/alpha/tutorials/sequences/nmt_with_attention\n",
        "  s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "  s = s.strip()\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  s = '<start> ' + s + ' <end>'\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_XD48hhgJ53",
        "colab_type": "code",
        "outputId": "ce4e02e3-912c-43f0-f863-cf551d12d72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Original:\", sentences[0])\n",
        "sentences = [(preprocess(source), preprocess(target)) for (source, target) in sentences]\n",
        "print(\"Preprocessed:\", sentences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: ['Go.', 'Ve.\\n']\n",
            "Preprocessed: ('<start> Go . <end>', '<start> Ve . <end>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BswiuexJgJ_O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#pair english & spanish\n",
        "source_sentences, target_sentences = list(zip(*sentences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "His8gJVWjiV2",
        "colab_type": "code",
        "outputId": "a5ae9be0-c2d2-45ec-f863-d4968b288391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "source_sentences[0],target_sentences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<start> Go . <end>', '<start> Ve . <end>')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "metadata": {
        "id": "dEavGQFDgKE4",
        "colab_type": "code",
        "outputId": "d2f47fff-a32c-440e-9344-38188d98d1a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "source_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_tokenizer.fit_on_texts(source_sentences)\n",
        "source_data = source_tokenizer.texts_to_sequences(source_sentences)\n",
        "print(\"Sequence:\", source_data[0])\n",
        "source_data = tf.keras.preprocessing.sequence.pad_sequences(source_data, padding='post')\n",
        "print(\"Padded:\", source_data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [1, 19, 3, 2]\n",
            "Padded: [ 1 19  3  2  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YEuOTzwegKC5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_tokenizer.fit_on_texts(target_sentences)\n",
        "target_data = target_tokenizer.texts_to_sequences(target_sentences)\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgA8z6CWgJ8h",
        "colab_type": "code",
        "outputId": "3a538f4e-970c-4060-ecd1-d9530f613d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels = np.zeros(target_data.shape)\n",
        "target_labels[:,0:target_data.shape[1] -1] = target_data[:,1:]\n",
        "\n",
        "print(\"Target sequence\", target_data[0])\n",
        "print(\"Target label\", target_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target sequence [ 1 71  3  2  0  0  0  0  0  0  0  0]\n",
            "Target label [71.  3.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3RslwJbDgJ3I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_vocab_size = len(source_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-EGQwVRgJ0m",
        "colab_type": "code",
        "outputId": "f26c27ad-7557-4ebe-c393-dd1e0a46f08b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "def decode(encoded, tokenizer):\n",
        "  for number in encoded:\n",
        "    if number !=0:\n",
        "      print (\"%d -> %s\" % (number, tokenizer.index_word[number]))\n",
        "      \n",
        "decode(source_data[0], source_tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> <start>\n",
            "19 -> go\n",
            "3 -> .\n",
            "2 -> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ah_5XbSGgJtI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices((source_data, target_data, target_labels)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T5sHioWfgjTv",
        "colab_type": "code",
        "outputId": "9d4e54a2-320e-409e-9916-168b8c7c5e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "example_batch = next(iter(dataset))\n",
        "source, target, taget_labels = example_batch\n",
        "print(\"Shapes:\", source.shape, target.shape, taget_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes: (5, 8) (5, 12) (5, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TAjcgsNxgjZ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 32\n",
        "rnn_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uz7reJWegjfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(source_vocab_size,\n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)        \n",
        "    return output, state\n",
        "  \n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, rnn_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKqdE4lEgjjl",
        "colab_type": "code",
        "outputId": "12727c3b-e9ae-449c-96fe-e128b1f68ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#call encoder\n",
        "# Create a batch of one sentence\n",
        "ex_sentence = tf.expand_dims(source_data[0], axis=0)\n",
        "ex_translation = tf.expand_dims(target_data[0], axis=0)\n",
        "ex_labels = tf.expand_dims(target_labels[0], axis=0)\n",
        "print(ex_sentence.shape)\n",
        "\n",
        "encoder = Encoder()\n",
        "hidden_state = encoder.init_state(batch_size=1)\n",
        "print(hidden_state.shape)\n",
        "\n",
        "output, hidden_state = encoder(ex_sentence, hidden_state)\n",
        "print(output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 8)\n",
            "(1, 64)\n",
            "(1, 8, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1YMBKMtLgjmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, \n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    logits = self.dense(output)\n",
        "    return logits, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "383IfCFRgjd1",
        "colab_type": "code",
        "outputId": "2f4dc46d-90fe-4b19-cb2a-32e0d9eb58e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#call decoder\n",
        "decoder = Decoder()\n",
        "decoder_output, decoder_state = decoder(ex_labels, hidden_state)\n",
        "print(decoder_output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 12, 2837)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hWimers-gjXP",
        "colab_type": "code",
        "outputId": "6e158bad-bd39-4188-d5ff-c10f2a2e7cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def calc_loss(targets, logits):\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  return crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "print(\"Loss\", calc_loss(ex_labels, decoder_output))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss tf.Tensor(1.9880537, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xuVjZhObg2X7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def translate(idx=None):\n",
        "  \n",
        "    if idx == None: \n",
        "      idx = np.random.choice(len(sentences))\n",
        "    \n",
        "    input_sent = source_data[idx]\n",
        "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "    \n",
        "    hidden_state = encoder.init_state(batch_size=1)\n",
        "    output, hidden_state = encoder(input_sent, hidden_state)\n",
        "    \n",
        "    decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "    out_words = []\n",
        "    \n",
        "    decoder_state = hidden_state\n",
        "\n",
        "    while True:\n",
        "      \n",
        "        decoder_output, decoder_state = decoder(decoder_input, decoder_state)\n",
        "        decoder_input = tf.argmax(decoder_output, -1)\n",
        "        word_idx = decoder_input.numpy()[0][0]\n",
        "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "        # before the decoder is trained, just stop translating and return\n",
        "        # what we have)\n",
        "        if word_idx == 0: \n",
        "          out_words.append('<end>')\n",
        "        else:\n",
        "          out_words.append(target_tokenizer.index_word[word_idx])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "          break\n",
        "          \n",
        "    translation = ' '.join(out_words)    \n",
        "    return sentences[idx][0], sentences[idx][1], translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kj3LHP_Bg2bF",
        "colab_type": "code",
        "outputId": "32bb6f48-8b96-40d3-857c-9d3227d09eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "input_sent, target_sent, translation = translate()\n",
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> Come on back . <end>\n",
            "Target: <start> Regresa . <end>\n",
            "Translation: tomad mujeres paraos chilles cuenta muevete persona maldicion grande pascua estaremos esos atras atras digo quedese boca asustado obeso obeso\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oMuxE6l2g2gm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-E5-xNPBg2kU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step(source_seq, target_seq, target_labels, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBoOzH_Bsfz3",
        "colab_type": "code",
        "outputId": "2b9d97b8-1134-4538-8113-3022c138d7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 8), (None, 12), (None, 12)), types: (tf.int32, tf.int32, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "metadata": {
        "id": "40tCzxcqg2oG",
        "colab_type": "code",
        "outputId": "dd9ef956-2417-4946-a261-7c84615a4a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 200\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states = encoder.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
        "      loss = train_step(source_seq, target_seq, target_labels, en_initial_states)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "      input_sent, target_sent, translation = translate()\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 1.4177, Time 17.21 sec\n",
            "Input: <start> Please hurry ! <end>\n",
            "Target: <start> Por favor , apurate ! <end>\n",
            "Translation: no es un libro . <end>\n",
            "\n",
            "Epoch #10, Loss 0.9472, Time 17.00 sec\n",
            "Input: <start> Come here . <end>\n",
            "Target: <start> Ven . <end>\n",
            "Translation: dejame terminar . <end>\n",
            "\n",
            "Epoch #20, Loss 0.6779, Time 17.19 sec\n",
            "Input: <start> He is skating . <end>\n",
            "Target: <start> Esta andando en patineta . <end>\n",
            "Translation: el esta demente . <end>\n",
            "\n",
            "Epoch #30, Loss 0.4333, Time 17.54 sec\n",
            "Input: <start> Don t cry . <end>\n",
            "Target: <start> No llores ! <end>\n",
            "Translation: no engordes . <end>\n",
            "\n",
            "Epoch #40, Loss 0.2485, Time 17.15 sec\n",
            "Input: <start> Hang on . <end>\n",
            "Target: <start> Agarra fuertemente . <end>\n",
            "Translation: bienvenido a casa . <end>\n",
            "\n",
            "Epoch #50, Loss 0.1806, Time 17.22 sec\n",
            "Input: <start> Have some tea . <end>\n",
            "Target: <start> Bebe un poco de te . <end>\n",
            "Translation: bebe un poco de te . <end>\n",
            "\n",
            "Epoch #60, Loss 0.1063, Time 17.07 sec\n",
            "Input: <start> I could walk . <end>\n",
            "Target: <start> Podria caminar . <end>\n",
            "Translation: podria nadar . <end>\n",
            "\n",
            "Epoch #70, Loss 0.0640, Time 16.78 sec\n",
            "Input: <start> Start here . <end>\n",
            "Target: <start> Empieza aqui . <end>\n",
            "Translation: empieza aqui . <end>\n",
            "\n",
            "Epoch #80, Loss 0.0629, Time 16.70 sec\n",
            "Input: <start> He s broke . <end>\n",
            "Target: <start> Esta arruinado . <end>\n",
            "Translation: esta sin blanca . <end>\n",
            "\n",
            "Epoch #90, Loss 0.0524, Time 17.22 sec\n",
            "Input: <start> I m okay . <end>\n",
            "Target: <start> Estoy perfectamente . <end>\n",
            "Translation: estoy perfectamente . <end>\n",
            "\n",
            "Epoch #100, Loss 0.0744, Time 17.32 sec\n",
            "Input: <start> Is it free ? <end>\n",
            "Target: <start> ¿ Es gratis ? <end>\n",
            "Translation: ¿ es eso ? <end>\n",
            "\n",
            "Epoch #110, Loss 0.0602, Time 17.29 sec\n",
            "Input: <start> Memorize this . <end>\n",
            "Target: <start> Memorizate esto . <end>\n",
            "Translation: memoriza esto . <end>\n",
            "\n",
            "Epoch #120, Loss 0.0301, Time 17.01 sec\n",
            "Input: <start> Tom lied . <end>\n",
            "Target: <start> Tom mintio . <end>\n",
            "Translation: tom mintio . <end>\n",
            "\n",
            "Epoch #130, Loss 0.1318, Time 16.56 sec\n",
            "Input: <start> We knew that . <end>\n",
            "Target: <start> Sabiamos eso . <end>\n",
            "Translation: lo sabiamos . <end>\n",
            "\n",
            "Epoch #140, Loss 0.0417, Time 16.61 sec\n",
            "Input: <start> Move over . <end>\n",
            "Target: <start> Mueve el culo . <end>\n",
            "Translation: deja sitio . <end>\n",
            "\n",
            "Epoch #150, Loss 0.0343, Time 17.02 sec\n",
            "Input: <start> It s . <end>\n",
            "Target: <start> Son las tres y diez . <end>\n",
            "Translation: son las . <end>\n",
            "\n",
            "Epoch #160, Loss 0.0448, Time 18.00 sec\n",
            "Input: <start> Hang on ! <end>\n",
            "Target: <start> Espera un momento ! <end>\n",
            "Translation: espera un momento ! <end>\n",
            "\n",
            "Epoch #170, Loss 0.0320, Time 17.02 sec\n",
            "Input: <start> I have orders . <end>\n",
            "Target: <start> Yo tengo ordenes . <end>\n",
            "Translation: yo tengo ordenes . <end>\n",
            "\n",
            "Epoch #180, Loss 0.0660, Time 17.29 sec\n",
            "Input: <start> Be merciful . <end>\n",
            "Target: <start> Se clemente . <end>\n",
            "Translation: se clemente . <end>\n",
            "\n",
            "Epoch #190, Loss 0.0474, Time 17.67 sec\n",
            "Input: <start> I like Tom . <end>\n",
            "Target: <start> Me agrada Tom . <end>\n",
            "Translation: me agrada tom . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y0Dklr7Kg2fS",
        "colab_type": "code",
        "outputId": "d8141610-13ce-4a9b-91d2-0223dd2fbff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#calculate BLEU score\n",
        "references, hypotheses = [], []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  input_sent, target_sent, translation = translate()\n",
        "  references.append(target_sent)\n",
        "  hypotheses.append(\"<start> \" + translation)\n",
        "  \n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses, [references])\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=37.02679818891001, counts=[21885, 11271, 5705, 2319], totals=[28682, 23682, 18682, 13682], precisions=[76.30221044557562, 47.59310869014441, 30.537415694251152, 16.949276421575792], bp=1.0, sys_len=28682, ref_len=28576)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "khWISC6xtzBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1uBmDXl9yEOW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}